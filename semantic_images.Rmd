---
title: "R Notebook"
output: html_notebook
---

Semantic images


Based on a talk I saw years ago which took an image, and did reverse image search, repeatedly, each time using the top images to find new ones.  The process unveiled the features (shape, colour, objects) that were "similar" to the image search, showing the semantic structure of image search.

I'm curious if something like this could work using a personal photo, to find semantically similar open licensed photos. 

AND how this could work with one's own images, to show similar images (but not like picasa did...)

This could also extract colour and use this abstraction as a representation.

For reverse image search, creative commons, google, and tineye should all be ok.

This creates a similary measure between images https://www.rdocumentation.org/packages/RNiftyReg/versions/2.7.0/topics/similarity 

To extract colours from an image use: https://chichacha.netlify.app/2019/01/19/extracting-colours-from-your-images-with-image-quantization/ 



```{r}



```
